sf::st_as_sf()
bg1
# generate background points
## this will need to be adjust if species if only present in a small area
bg1 <- sf::st_sample(x = natArea, size = 5000)%>%
sf::st_as_sf()
bg1$presence <- 1
bg1
# generate background points
## this will need to be adjust if species if only present in a small area
bg1 <- sf::st_sample(x = natArea, size = 5000)%>%
sf::st_as_sf()%>%
mutate(presence == 0)%>%
select(presence, geometry = x)
# generate background points
## this will need to be adjust if species if only present in a small area
bg1 <- sf::st_sample(x = natArea, size = 5000)%>%
sf::st_as_sf()%>%
mutate(presence == 0)
# generate background points
## this will need to be adjust if species if only present in a small area
bg1 <- sf::st_sample(x = natArea, size = 5000)%>%
sf::st_as_sf()%>%
mutate("presence" == 0)
bg1
# generate background points
## this will need to be adjust if species if only present in a small area
bg1 <- sf::st_sample(x = natArea, size = 5000)%>%
sf::st_as_sf()%>%
mutate("presence" = 0)
bg1
# generate background points
## this will need to be adjust if species if only present in a small area
bg1 <- sf::st_sample(x = natArea, size = 5000)%>%
sf::st_as_sf()%>%
mutate("presence" = 0)%>%
select(presence, x = "geometry")
# generate background points
## this will need to be adjust if species if only present in a small area
bg1 <- sf::st_sample(x = natArea, size = 5000)%>%
sf::st_as_sf()%>%
mutate("presence" = 0)%>%
select(presence,"geometry" = x)
bg1
speciesPoints
names(sp1)
# test for same coordinates against the presense points, drop any overlap
sp1 <- speciesPoints %>%
mutate("presence" = 1)%>%
select(presence,geometry)
so1
sp1
bg1$geometry %in% sp1$geometry
# generate background points
## this will need to be adjust if species if only present in a small area
bg1 <- sf::st_sample(x = natArea, size = 5000)%>%
sf::st_as_sf()%>%
mutate("presence" = 0)%>%
select(presence,"geometry" = x)%>%
filter(!geometry %in% sp1$geometry)
dim(bg1)
# bind datasets
d1 <- bind_rows(sp1, bg1)
# bind datasets
d1 <- bind_rows(sp1, bg1)
# extract values from rasters
d2 <- terra::extract(x = bioVars, y = vect(d1))
d2
View(d2)
?extract
class(d2)
# extract values from rasters
d2 <- terra::extract(x = bioVars, y = vect(d1), bind= TRUE)
d2
View(d2)
d2
View(d2@ptr)
View(d2@ptr@.xData)
generateModelData <- function(speciesPoints,natArea,bioVars){
# generate background points
## format species data
sp1 <- speciesPoints %>%
mutate("presence" = 1)%>%
select(presence,geometry)
## this will need to be adjust if species if only present in a small area
bg1 <- sf::st_sample(x = natArea, size = 5000)%>%
sf::st_as_sf()%>%
mutate("presence" = 0)%>%
select(presence,"geometry" = x)%>%
filter(!geometry %in% sp1$geometry) # test for same coordinated between presence and background data
# bind datasets
d1 <- bind_rows(sp1, bg1)
# extract values from rasters
## I don't know if I need this a spatial object at this point, I don't thin so
## Also this are no reference values for what points aligns with which input location.
d2 <- terra::extract(x = bioVars, y = vect(d1), bind= TRUE)
return(d2)
}
## spatial object
sp1 <- createSF_Objects(speciesData = sd1)%>%
removeDuplicates()
#srsex
srsex <- srs_exsitu(sp_counts = c1)
## define natural area based on ecoregions
natArea <- nat_area_shp(speciesPoints = sp1, ecoregions = ecoregions)
## generate GA50 objects
g_buffer <- create_buffers(speciesPoints = sp1,natArea = natArea,
bufferDist = bufferDist,templateRast = templateRast)
## generate modeling data
m_Data <- generateModelData(speciesPoints = sp1, natArea = natArea,bioVars = bioVars)
qtm(m_Data)
clasS(m_data)
clasS(m_Data)
m_Data
class(m_data)
class(m_data)
class(m_Data)
generateModelData <- function(speciesPoints,natArea,bioVars){
# generate background points
## format species data
sp1 <- speciesPoints %>%
mutate("presence" = 1)%>%
select(presence,geometry)
## this will need to be adjust if species if only present in a small area
bg1 <- sf::st_sample(x = natArea, size = 5000)%>%
sf::st_as_sf()%>%
mutate("presence" = 0)%>%
select(presence,"geometry" = x)%>%
filter(!geometry %in% sp1$geometry) # test for same coordinated between presence and background data
# bind datasets
d1 <- bind_rows(sp1, bg1)
# extract values from rasters
## I don't know if I need this a spatial object at this point, I don't thin so
## Also this are no reference values for what points aligns with which input location.
d2 <- terra::extract(x = bioVars, y = vect(d1), bind= TRUE)
return(st_as_sf(d2))
}
## generate modeling data
m_Data <- generateModelData(speciesPoints = sp1, natArea = natArea,bioVars = bioVars)
m_data
m_Data
qtm(m_Data)
modelData <- m_data
modelData <- m_Data
modelData
# subset predictor data and presence column
varSelect <- modelData %>% dplyr::select(-geometry)
varSelect
# subset predictor data and presence column
varSelect <- modelData %>% st_drop_geometry()
varSelect
# remove all na from dataframe
test2 <-complete.cases(varSelect)
test2
varSelect <- varSelect[test2,]
varSelect
# drop all column from bioValues set as well so the same data is used for maxnet modeling.
bioValues <- modelData[test2,]
names(bioValues)
# # #vsurf
### Considered altering the number of trees, 100 is somewhat low for the
# number of predictors used. It was a time concern more then anything.
# vsurfThres <- VSURF_thres(x=bioValues[,1:26] , y=as.factor(bioValues$presence) ,
#                           ntree = 100 )
### change for 30 arc second run
vsurfThres <- VSURF_thres(x=bioValues[,1:27] , y=as.factor(bioValues$presence) ,
ntree = 100 )
bioValues$presence
bioValues[,2:27]
names(bioValues)
ioValues[,2:27
bioValues[,2:27]
bioValues[,2:27]
# drop all column from bioValues set as well so the same data is used for maxnet modeling.
bioValues <- varSelect[test2,]
names(bioValues)
# # #vsurf
### Considered altering the number of trees, 100 is somewhat low for the
# number of predictors used. It was a time concern more then anything.
# vsurfThres <- VSURF_thres(x=bioValues[,1:26] , y=as.factor(bioValues$presence) ,
#                           ntree = 100 )
### change for 30 arc second run
vsurfThres <- VSURF_thres(x=bioValues[,2:27] , y=as.factor(bioValues$presence) ,
ntree = 100 )
View(bioValues)
# # #vsurf
### Considered altering the number of trees, 100 is somewhat low for the
# number of predictors used. It was a time concern more then anything.
# vsurfThres <- VSURF_thres(x=bioValues[,1:26] , y=as.factor(bioValues$presence) ,
#                           ntree = 100 )
### change for 30 arc second run
vsurfThres <- VSURF_thres(x=bioValues[1:100,2:27] , y=as.factor(bioValues$presence) ,
ntree = 100 )
bioValues[1:100,2:27]
# # #vsurf
### Considered altering the number of trees, 100 is somewhat low for the
# number of predictors used. It was a time concern more then anything.
# vsurfThres <- VSURF_thres(x=bioValues[,1:26] , y=as.factor(bioValues$presence) ,
#                           ntree = 100 )
### change for 30 arc second run
vsurfThres <- VSURF_thres(x=bioValues[1:100,2:27] , y=as.factor(bioValues$presence[1:100]) ,
ntree = 100 )
vsurfThres
# # #vsurf
### Considered altering the number of trees, 100 is somewhat low for the
# number of predictors used. It was a time concern more then anything.
# vsurfThres <- VSURF_thres(x=bioValues[,1:26] , y=as.factor(bioValues$presence) ,
#                           ntree = 100 )
### change for 30 arc second run
vsurfThres <- VSURF_thres(x=bioValues[,2:27] , y=as.factor(bioValues$presence) ,
ntree = 100 )
bioValues$presence
unique(bioValues$presence)
View(bioValues)
# subset predictor data and presence column
varSelect <- modelData %>% st_drop_geometry()
# remove all na from dataframe
test2 <-complete.cases(varSelect)
length(test2)
dim(modelData)
# drop all column from bioValues set as well so the same data is used for maxnet modeling.
bioValues <- varSelect[test2,]
dim(bioValues)
View(bioValues)
# # #vsurf
### Considered altering the number of trees, 100 is somewhat low for the
# number of predictors used. It was a time concern more then anything.
# vsurfThres <- VSURF_thres(x=bioValues[,1:26] , y=as.factor(bioValues$presence) ,
#                           ntree = 100 )
### change for 30 arc second run
vsurfThres <- VSURF_thres(x=bioValues[,2:27] , y=as.factor(bioValues$presence) ,
ntree = 100 )
# # #vsurf
### Considered altering the number of trees, 100 is somewhat low for the
# number of predictors used. It was a time concern more then anything.
# vsurfThres <- VSURF_thres(x=bioValues[,1:26] , y=as.factor(bioValues$presence) ,
#                           ntree = 100 )
### change for 30 arc second run
vsurfThres <- VSURF_thres(x=bioValues[,2:27] , y=as.factor(bioValues$presence) ,
ntree.thres = 100,parallel = TRUE )
vsurfThres
?VSURF_thres
# define predictor list based on Run
inputPredictors <- vsurfThres$varselect.thres
inputPredictors
varSelect
names(varSelect)
# subset predictor data and presence column
varSelect <- modelData %>% st_drop_geometry() %>% select(-presence)
varSelect
names(varSelect)
# remove all na from dataframe
test2 <-complete.cases(varSelect)
# drop all column from bioValues set as well so the same data is used for maxnet modeling.
bioValues <- varSelect[test2,]
# drop all column from bioValues set as well so the same data is used for maxnet modeling.
bioValues <- modelData[test2,] %>% st_drop_geometry()
names(bioValues)
# # #vsurf
### Considered altering the number of trees, 100 is somewhat low for the
# number of predictors used. It was a time concern more then anything.
# vsurfThres <- VSURF_thres(x=bioValues[,1:26] , y=as.factor(bioValues$presence) ,
#                           ntree = 100 )
### change for 30 arc second run
vsurfThres <- VSURF_thres(x=bioValues[,2:27] , y=as.factor(bioValues$presence) ,
ntree.thres = 100, parallel = TRUE )
vsurfThres
# define predictor list based on Run
inputPredictors <- vsurfThres$varselect.thres
inputPredictors
# ordered predictors from our variable selection
predictors <- varSelect[,c(inputPredictors)]
predictors
names(predictors)
# Calculate correlation coefficient matrix
correlation <-cor(predictors, method="pearson")
# #define the list of top 15 predictors
varNames <- colnames(correlation)
varNames
correlation
# ordered predictors from our variable selection
predictors <- varSelect[,c(inputPredictors)]
View(predictors)
# subset predictor data and presence column
varSelect <- modelData %>% st_drop_geometry() %>% select(-presence)
# remove all na from dataframe
test2 <-complete.cases(varSelect)
# drop all column from bioValues set as well so the same data is used for maxnet modeling.
bioValues <- modelData[test2,] %>% st_drop_geometry()
dim(bioValues)
dim(varSelect)
# subset predictor data and presence column
varOnly <- modelData %>% st_drop_geometry() %>% select(-presence)
# remove all na from dataframe
test2 <-complete.cases(varOnly)
# drop all column from bioValues set as well so the same data is used for maxnet modeling.
bioValues <- modelData[test2,] %>% st_drop_geometry()
# redefine var select to in
varSelect <- bioValues %>% st_drop_geometry() %>% select(-presence)
# # #vsurf
### Considered altering the number of trees, 100 is somewhat low for the
# number of predictors used. It was a time concern more then anything.
# vsurfThres <- VSURF_thres(x=bioValues[,1:26] , y=as.factor(bioValues$presence) ,
#                           ntree = 100 )
### change for 30 arc second run
vsurfThres <- VSURF_thres(x=bioValues[,2:27] , y=as.factor(bioValues$presence) ,
ntree.thres = 100, parallel = TRUE )
# define predictor list based on Run
inputPredictors <- vsurfThres$varselect.thres
# ordered predictors from our variable selection
predictors <- varSelect[,c(inputPredictors)]
# Calculate correlation coefficient matrix
correlation <-cor(predictors, method="pearson")
correlation
View(correlation)
# #define the list of top 15 predictors
varNames <- colnames(correlation)
# empty list containing the variables tested
varsTested <- c()
#loop through the top 5 predictors to remove correlated varables.
for( i in 1:5){
print(varNames[i])
if(varNames[i] %in% varNames){
# add variable to the test list
varsTested <- c(varsTested, varNames[i])
# Test for correlations with predictors
vars <- correlation[(i+1):nrow(correlation),i] > 0.7 | correlation[(i+1):nrow(correlation),i] < -0.7
# Select correlated values names
corVar <- names(which(vars == TRUE))
#test is any correlated variables exist
if(length(corVar) >0 ){
# loop through the list of correlated variables
varNames <- varNames[!varNames  %in% corVar]
print(paste0("the variable ", corVar, " was removed"))
}
}else{
print("this variable has been removed already")
}
}
# include all variables that were tested.
for(p in varsTested){
if(p %in% varNames){
}else{
varNames <- c(varNames, p)
}
}# It's a little bit confusing why variable are being dropped after they area tested. Correlation
#create a dataframe of the top predictors and
rankPredictors <- data.frame(matrix(nrow = length(colnames(correlation)),ncol = 3))
rankPredictors$varNames <- colnames(correlation)
rankPredictors$importance <- vsurfThres$imp.varselect.thres
rankPredictors$includeInFinal <- colnames(correlation) %in% varNames
rankPredictors <- rankPredictors[,4:6]
rankPredictors
variblesToModel <- varSelect[,varNames]
variblesToModel
View(variblesToModel)
varNames
?list
varaibleSelection <- function(modelData){
# subset predictor data and presence column
varOnly <- modelData %>% st_drop_geometry() %>% select(-presence)
# remove all na from dataframe
test2 <-complete.cases(varOnly)
# drop all column from bioValues set as well so the same data is used for maxnet modeling.
bioValues <- modelData[test2,] %>% st_drop_geometry()
# redefine var select to in
varSelect <- bioValues %>% st_drop_geometry() %>% select(-presence)
# Maximum modelled data
#write.csv(x = bioValues, file = paste0(sp_dir, "/modeling/maxent/bioValuesForPresencePoints.csv"))
# # #vsurf
### Considered altering the number of trees, 100 is somewhat low for the
# number of predictors used. It was a time concern more then anything.
# vsurfThres <- VSURF_thres(x=bioValues[,1:26] , y=as.factor(bioValues$presence) ,
#                           ntree = 100 )
### change for 30 arc second run
vsurfThres <- VSURF_thres(x=bioValues[,2:27] , y=as.factor(bioValues$presence) ,
ntree.thres = 100, parallel = TRUE )
###
#correlation matrix
###
# define predictor list based on Run
inputPredictors <- vsurfThres$varselect.thres
# ordered predictors from our variable selection
predictors <- varSelect[,c(inputPredictors)]
# Calculate correlation coefficient matrix
correlation <-cor(predictors, method="pearson")
#change self correlation value
# #define the list of top 15 predictors
varNames <- colnames(correlation)
# empty list containing the variables tested
varsTested <- c()
#loop through the top 5 predictors to remove correlated varables.
for( i in 1:5){
print(varNames[i])
if(varNames[i] %in% varNames){
# add variable to the test list
varsTested <- c(varsTested, varNames[i])
# Test for correlations with predictors
vars <- correlation[(i+1):nrow(correlation),i] > 0.7 | correlation[(i+1):nrow(correlation),i] < -0.7
# Select correlated values names
corVar <- names(which(vars == TRUE))
#test is any correlated variables exist
if(length(corVar) >0 ){
# loop through the list of correlated variables
varNames <- varNames[!varNames  %in% corVar]
print(paste0("the variable ", corVar, " was removed"))
}
}else{
print("this variable has been removed already")
}
}
# include all variables that were tested.
for(p in varsTested){
if(p %in% varNames){
}else{
varNames <- c(varNames, p)
}
}# It's a little bit confusing why variable are being dropped after they area tested. Correlation
# should be the same in both directs. This is just a test to make sure it works.
#create a dataframe of the top predictors and
rankPredictors <- data.frame(matrix(nrow = length(colnames(correlation)),ncol = 3))
rankPredictors$varNames <- colnames(correlation)
rankPredictors$importance <- vsurfThres$imp.varselect.thres
rankPredictors$includeInFinal <- colnames(correlation) %in% varNames
rankPredictors <- rankPredictors[,4:6]
write.csv(x = rankPredictors, file = paste0(sp_dir, "/modeling/maxent/predictorImportance.csv"))
variblesToModel <- varSelect[,varNames]
return(list(
rankPredictors = rankPredictors,
variblesToModel = variblesToModel
))
}
## generate modeling data
m_data <- generateModelData(speciesPoints = sp1, natArea = natArea,bioVars = bioVars)
v_data <- varaibleSelection(modelData = m_data)
varaibleSelection <- function(modelData){
# subset predictor data and presence column
varOnly <- modelData %>% st_drop_geometry() %>% select(-presence)
# remove all na from dataframe
test2 <-complete.cases(varOnly)
# drop all column from bioValues set as well so the same data is used for maxnet modeling.
bioValues <- modelData[test2,] %>% st_drop_geometry()
# redefine var select to in
varSelect <- bioValues %>% st_drop_geometry() %>% select(-presence)
# Maximum modelled data
#write.csv(x = bioValues, file = paste0(sp_dir, "/modeling/maxent/bioValuesForPresencePoints.csv"))
# # #vsurf
### Considered altering the number of trees, 100 is somewhat low for the
# number of predictors used. It was a time concern more then anything.
# vsurfThres <- VSURF_thres(x=bioValues[,1:26] , y=as.factor(bioValues$presence) ,
#                           ntree = 100 )
### change for 30 arc second run
vsurfThres <- VSURF_thres(x=bioValues[,2:27] , y=as.factor(bioValues$presence) ,
ntree.thres = 100, parallel = TRUE )
###
#correlation matrix
###
# define predictor list based on Run
inputPredictors <- vsurfThres$varselect.thres
# ordered predictors from our variable selection
predictors <- varSelect[,c(inputPredictors)]
# Calculate correlation coefficient matrix
correlation <-cor(predictors, method="pearson")
#change self correlation value
# #define the list of top 15 predictors
varNames <- colnames(correlation)
# empty list containing the variables tested
varsTested <- c()
#loop through the top 5 predictors to remove correlated varables.
for( i in 1:5){
print(varNames[i])
if(varNames[i] %in% varNames){
# add variable to the test list
varsTested <- c(varsTested, varNames[i])
# Test for correlations with predictors
vars <- correlation[(i+1):nrow(correlation),i] > 0.7 | correlation[(i+1):nrow(correlation),i] < -0.7
# Select correlated values names
corVar <- names(which(vars == TRUE))
#test is any correlated variables exist
if(length(corVar) >0 ){
# loop through the list of correlated variables
varNames <- varNames[!varNames  %in% corVar]
print(paste0("the variable ", corVar, " was removed"))
}
}else{
print("this variable has been removed already")
}
}
# include all variables that were tested.
for(p in varsTested){
if(p %in% varNames){
}else{
varNames <- c(varNames, p)
}
}# It's a little bit confusing why variable are being dropped after they area tested. Correlation
# should be the same in both directs. This is just a test to make sure it works.
#create a dataframe of the top predictors and
rankPredictors <- data.frame(matrix(nrow = length(colnames(correlation)),ncol = 3))
rankPredictors$varNames <- colnames(correlation)
rankPredictors$importance <- vsurfThres$imp.varselect.thres
rankPredictors$includeInFinal <- colnames(correlation) %in% varNames
rankPredictors <- rankPredictors[,4:6]
# write.csv(x = rankPredictors, file = paste0(sp_dir, "/modeling/maxent/predictorImportance.csv"))
variblesToModel <- varSelect[,varNames]
return(list(
allModelData = bioValues,
rankPredictors = rankPredictors,
variblesToModel = variblesToModel
))
}
v_data <- varaibleSelection(modelData = m_data)
v_data
