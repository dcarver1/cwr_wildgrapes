)
if(nrow(test) >0 ){
print(paste0("removed", row))
d1 <- d1[!d1$index == test$index, ]
}
}
dim(d2)
dim(d1)
# bind the data back in
d7 <- bind_rows(d1,d2)
dim(d7)
# remove midwest herb
d8 <- d7[!d7$databaseSource == "Midwest Herbaria 2019", ]
d8
dim(d8)
t1<- read_csv("data/processed_occurrence/model_data072025_edit.csv")
dim(t1)
View(d8)
df2_a <- uniqueTaxon |>
purrr::map(.f = removeDups, data = df2) |>
bind_rows()
View(df2_a)
write_csv(x = df2, file = "data/processed_occurrence/allEvaluated_data072025.csv")
write_csv(x = df2_a, file = "data/processed_occurrence/allEvaluated_data_removedDups_072025.csv")
# a2 <- alteredData |>
#   dplyr::filter(nchar(alteredData$`Record ID for point`) > 2)|>
#   dplyr::filter(!is.na(Taxon))
#
# # exclude from the input datasets
# speciesData3 <- speciesData[!c(speciesData$recordID %in% a2$`Record ID for point`), ]
# speciesData <- speciesData3
# export for gap r testing
# write.csv(speciesData, file = "temp/allVitisData082025.csv")
## doubled check and this data seems to have less duplication of G values
speciesData <- read_csv("temp/allVitisData082025.csv")
dim(speciesData)
d3 <- checksOnLatLong(df2)
dim(df2_a)
d3 <- checksOnLatLong(df2)
dim(d3)
d3
d3$validLatLon
dim(d3$validLatLon)
dim(d3$countycheck)
## grab the G records with no lat lon values
d3_g <- d3$countycheck |>
dplyr::mutate(
county = stringr::str_remove_all(string = county,pattern = " .Co"),
county = stringr::str_remove_all(string = county,pattern = " Co."),
county = case_when(
grepl("County", county) ~ county,
is.na(county) ~ NA,
TRUE ~ paste0(county," County")
)
)
d3_g
View(dg_3)
View(d3_g)
## grab the G records with no lat lon values
d3_g <- d3$countycheck |>
dplyr::mutate(
county = stringr::str_remove_all(string = county,pattern = " .Co"),
county = stringr::str_remove_all(string = county,pattern = " Co."),
county = case_when(
grepl("County", county) ~ county,
is.na(county) ~ NA,
TRUE ~ paste0(county," County")
)|>
dplyr::filter(type =="G")
)
## grab the G records with no lat lon values
d3_g <- d3$countycheck |>
dplyr::mutate(
county = stringr::str_remove_all(string = county,pattern = " .Co"),
county = stringr::str_remove_all(string = county,pattern = " Co."),
county = case_when(
grepl("County", county) ~ county,
is.na(county) ~ NA,
TRUE ~ paste0(county," County")
))|>
dplyr::filter(type =="G")
d3_g
VieW(d3_g)
View(d3_g)
### has lat lon so can be used in both county and modeling products
valLatLon <- d3$validLatLon
# add the G records with no lat lon back to the modeling data---------------------------------------
d6 <- valLatLon |> bind_rows(d3_g)
dim(d6)
single
#more duplicate checks
d <- d6[!duplicated(d6[,c("taxon", "databaseSource" , "sourceUniqueID")]), ]
dim(d6)
dim(d)
## grab the G records with no lat lon values
d3_g <- d3$countycheck |>
dplyr::mutate(
county = stringr::str_remove_all(string = county,pattern = " .Co"),
county = stringr::str_remove_all(string = county,pattern = " Co."),
county = case_when(
grepl("County", county) ~ county,
is.na(county) ~ NA,
TRUE ~ paste0(county," County")
))
# add the G records with no lat lon back to the modeling data---------------------------------------
d6 <- valLatLon |> bind_rows(d3_g)
dim(d6)
#more duplicate checks
d <- d6[!duplicated(d6[,c("taxon", "databaseSource" , "sourceUniqueID")]), ]
dim(d)
VieW(d6)
VieW(dt)
VieW(d6)
View(d6)
View(d)
# add the G records with no lat lon back to the modeling data---------------------------------------
d6 <- valLatLon |> bind_rows(d3_g)
View(d6)
file <- read_csv("data/source_data/mexicoRecords_ck.csv")
#
d1 <- file |>
dplyr::select(
taxon = "Taxon",
originalTaxon = "Possible Species ID",
# genus = "Vitis",
"latitude"  = Latitude,
"longitude" = Longitude,
sourceUniqueID = Genotype,
type = Type,
state  = State,
localityInformation = Locality,
collectionSource = "Holding Institute",
observerName = Source,
"Collecting number"
) |>
tidyr::separate( col = taxon, into = c("genus", "species"), sep = " ", remove = FALSE)
d1
d1 <- read_csv(files[1])
files <- list.files("data/jWen_data2025",
full.names = TRUE)
d1 <- read_csv(files[1])
dim(d1)
paste0(1:12,"_sourceID")
# process Dataset from june Wen  ------------------------------------------
processJun <- function(){
files <- list.files("data/jWen_data2025",
full.names = TRUE)
d1 <- read_csv(files[1]) |>
dplyr::select(
collectionSource = Collection,
state = State,
latitude = Latitude,
longitude = Longitude,
localityInformation = `Terra-i`
)|>
dplyr::mutate(
taxon = "Vitis martineziana",
originalTaxon = "Vitis martineziana",
genus = "Vitis",
species = "martineziana",
observerName = "Jun Wen",
iso3 = "MEX",
country = "Mexico",
type = "H",
databaseSource = "Personal Communication with Jun Wen",
sourceUniqueID = paste0("sourceID_",1:12),
)
d2 <- read_csv(files[2])  |>
dplyr::select(
collectionSource = Collection,
state = State,
latitude = Latitude,
longitude = Longitude,
localityInformation = `Terri-i`
)|>
dplyr::mutate(
taxon = "Vitis rubriflora",
originalTaxon = "Vitis rubriflora",
genus = "Vitis",
species = "rubriflora",
observerName = "Jun Wen",
iso3 = "MEX",
country = "Mexico",
type = "H",
databaseSource = "Personal Communication with Jun Wen"
)
output <- data.frame(matrix(nrow = 0, ncol = 25))
names <- c(
"taxon","originalTaxon","genus","species","latitude", "longitude","databaseSource",
"institutionCode","type","sourceUniqueID", "sampleCategory","country","iso3",
"localityInformation","biologicalStatus","collectionSource","finalOriginStat",
"yearRecorded","county","countyFIPS","state","stateFIPS","coordinateUncertainty",
"observerName","recordID"
)
output <- data.frame(setNames(lapply(names, function(x) character()), names), stringsAsFactors = FALSE)
output$latitude <- as.numeric(output$latitude)
output$longitude <- as.numeric(output$longitude)
# bind data together
output <- output |>
bind_rows(d1, d2)
return(output)
}
pacman::p_load(dplyr, readr, sf, terra, rgbif, googledrive, countrycode,
stringr)
# new vitis data
vitis2 <- read_csv("data/New World Vitis.csv")|>
dplyr::select(
"taxon" = "Scientific Name",
"acceptedSynonym" = "Names to include in this concept (Homotypic synonyms)",
"Names to exclude from this concept" = "Names to exclude from this concept" ,
"modelSpecies"    =  "Include in gap analysis?"
)
# General changes to taxonomy
# include data for missing species
# 1. New pull of data from GBIF
# 2. Update the filtering and synonym methods to account for changes in taxonomic relationships
# 3. rerender more at 1km resolutions for all species
# replicated what was generate in the compileInputDatasets.R script here just to
# have a clean start
# call in all new functions
source("preprocessing/functions/preprocessing07_2025Functions.R")
# call in specific require functions that were not altered
source("preprocessing/functions/process_gbif.R")
source("preprocessing/functions/helperFunctions.R")
# global variables  -------------------------------------------------------
standardColumnNames <- c(
"taxon","originalTaxon","genus","species","latitude","longitude","databaseSource",
"institutionCode","type","sourceUniqueID","sampleCategory","country","iso3",
"localityInformation","biologicalStatus","collectionSource","finalOriginStat",
"yearRecorded","county","countyFIPS","state","stateFIPS","coordinateUncertainty",
"observerName","recordID"
)
# Download gbif data from google drive ------------------------------------
pullGBIFFromDrive(run=FALSE)
# process the GBIF data  ---------------------------------------
# gbif
gbif <- processGBIF(path = "data/source_data/vitisGBIFDownload_20250721.csv") |>
orderNames(names = standardColumnNames) |>
removeDuplicatesID()
# write out data
write_csv(x = gbif, file = "data/processed_occurrence/gbif_072025.csv")
# process data from Jun  --------------------------------------------------
jun <- processJun() |>
orderNames(names = standardColumnNames) |>
removeDuplicatesID()
# add single record
single <- data.frame(matrix(nrow = 1, ncol = length(standardColumnNames)))
names(single) <- standardColumnNames
single$taxon <- "Vitis bloodworthiana"
single$observerName <-  "Facultad de Estudios Superiores Iztacala, UNAM, (FESI-UNAM), Mexico"
single$originalTaxon <- "Vitis bloodworthiana"
single$genus <- "Vitis"
single$species <- "bloodworthiana"
single$type <- "G"
single$latitude <-  "18.00"# "18.876888776"
single$longitude <- "-100.00"  # "-100.306249885"
single$localityInformation <- "Generalized lat lon per curator's request"
single$databaseSource <- "MBG"
single$institutionCode <- "MBG"
jun <- bind_rows(jun, single)
# write out data
write_csv(x = jun, file = "data/processed_occurrence/jun_072025.csv")
# processing Mexico accessions  -------------------------------------------
mex <- processMex()
# write out data
write_csv(x = mex, file = "data/processed_occurrence/mexicoRecords_082025.csv")
# update genesys data
gen <- processGenesysUpdate(path = "data/source_data/GenesysPGR_Vitis_subset.csv") |>
orderNames(names = standardColumnNames) |>
removeDuplicatesID()
# write out data
write_csv(x = gen, file = "data/processed_occurrence/genesys_072025.csv")
# read in all other datasets ----------------------------------------------
df <- readAndBind(run = TRUE) |>
dplyr::select(-`Collecting number`)
# martineziana present
# drop specific datasets based on source  ---------------------------------
df <- df |>
dplyr::filter(
!databaseSource %in% c("FAO 2019 (WIEWS)",
"GBIF 2019",
"Global Crop Diversity Trust 2019a (Genesys)",
"Global Crop Diversity Trust 2019b  (Cwr Occ)",
"USDA ARS NPGS 2019a",
"Midwest Herbaria 2019")
)
View(df)
# martineziana present
# Standardize names ( genus, species)  ------------------------------------
source("preprocessing/functions/standardizeNames.R")
## does not filter out data
## preforms text check steps. Structure, capilatization, etc
df1 <- standardizeNames(df)
# martineziana present
# species filter and synonym check  ---------------------------------------
source("preprocessing/functions/speciesStandardization.R")
## exclude any species not used in either the county or sdm appoach
datasets <- speciesCheck(data = df1, synonymList = vitis2)
df2 <- datasets$includedData
# martineziana present
novogranatensis <- df2[df2$taxon == "Vitis novogranatensis" ,]
# export the dataset to be used in the SRSex
# Remove duplicated data --------------------------------------------------
uniqueTaxon <- unique(df2$taxon)
# 40 taxon here
source("preprocessing/functions/removeDupsAcrossDatasets.R")
df2_a <- uniqueTaxon |>
purrr::map(.f = removeDups, data = df2) |>
bind_rows()
# add back in novo
df2_a <- bind_rows(df2_a, novogranatensis)
write_csv(x = df2, file = "data/processed_occurrence/allEvaluated_data072025.csv")
write_csv(x = df2_a, file = "data/processed_occurrence/allEvaluated_data_removedDups_072025.csv")
# Checks on the lat lon  --------------------------------------------------
# Lat long based quality checks  ------------------------------------------
source("preprocessing/functions/checksOnLatLong.R")
d3 <- checksOnLatLong(df2)
## grab the G records with no lat lon values
d3_g <- d3$countycheck |>
dplyr::mutate(
county = stringr::str_remove_all(string = county,pattern = " .Co"),
county = stringr::str_remove_all(string = county,pattern = " Co."),
county = case_when(
grepl("County", county) ~ county,
is.na(county) ~ NA,
TRUE ~ paste0(county," County")
))
### has lat lon so can be used in both county and modeling products
valLatLon <- d3$validLatLon
# add the G records with no lat lon back to the modeling data---------------------------------------
d6 <- valLatLon |> bind_rows(d3_g)
View(d6)
#more duplicate checks
d <- d6[!duplicated(d6[,c("taxon", "databaseSource" , "sourceUniqueID")]), ]
View(d)
# a2 <- alteredData |>
#   dplyr::filter(nchar(alteredData$`Record ID for point`) > 2)|>
#   dplyr::filter(!is.na(Taxon))
#
# # exclude from the input datasets
# speciesData3 <- speciesData[!c(speciesData$recordID %in% a2$`Record ID for point`), ]
# speciesData <- speciesData3
# export for gap r testing
# write.csv(speciesData, file = "temp/allVitisData082025.csv")
## doubled check and this data seems to have less duplication of G values
speciesData <- read_csv("temp/allVitisData082025.csv")
View(speciesData)
# remove midwest herb
d8 <- d[!d$databaseSource == "Midwest Herbaria 2019", ]
dim(d)
dim(d8)
write_csv(x = d8, file = "data/processed_occurrence/model_data072025_edit.csv")
t1<- read_csv("temp/allVitisData082025.csv")
head(d8)
dim(d8)
dim(t1)
dim(d8) - dim(t1)
write_csv(x = d8, file = "data/processed_occurrence/model_data122025.csv")
names(d8)
names(t1)
View(t1)
# get counts per taxon and compare to see what needs alterations
t8 <- d8 |>
dplyr::group_by("taxon")|>
dplyr::count( sort =TRUE)
t8
# get counts per taxon and compare to see what needs alterations
t8 <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)
t8
# get counts per taxon and compare to see what needs alterations
newCounts <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)
prevCounts <- t1 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)
prevCounts
prevCounts <- t1 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE) |>
dplyr::select(previousCount = n) |>
dplyr::left_join(newCounts, by = "taxon")
View(prevCounts)
# get counts per taxon and compare to see what needs alterations
newCounts <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)|>
dplyr::select(newCount = n)
prevCounts <- t1 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE) |>
dplyr::select(previousCount = n) |>
dplyr::left_join(newCounts, by = "taxon") |>
dplyr::mutate(diff = previousCount - newCount)
View(prevCounts)
prevCounts <- t1 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE) |>
dplyr::select(previousCount = n) |>
dplyr::left_join(newCounts, by = "taxon") |>
dplyr::mutate(diff = newCount - previousCount)
View(prevCounts)
newCounts <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)|>
dplyr::select(newCount = n)|>
dplyr::left_join(prevCounts, by = "taxon") |>
dplyr::mutate(diff = newCount - previousCount)
newCounts <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)|>
dplyr::select(newCount = n)|>
dplyr::left_join(prevCounts, by = "taxon") |>
dplyr::mutate(diff = newCount - previousCount)
newCounts <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)|>
dplyr::select(newCount = n)
d8
newCounts <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)|>
dplyr::select(newCount = n)
newCounts
prevCounts
# get counts per taxon and compare to see what needs alterations
prevCounts <- t1 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE) |>
dplyr::select(previousCount = n) |>
dplyr::filter(!is.na(taxon))
prevCounts
newCounts <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)|>
dplyr::select(newCount = n)
names(newCounts)
newCounts <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)|>
dplyr::select(newCount = n) |>
dplyr::left_join(prevCounts, by = "taxon") |>
dplyr::mutate(diff = newCount - previousCount)
View(newCounts)
# get counts per taxon and compare to see what needs alterations
prevCounts <- t1 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE) |>
dplyr::select(previousCount = n) |>
dplyr::filter(!is.na(taxon))
newCounts <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)|>
dplyr::select(newCount = n) |>
dplyr::left_join(prevCounts, by = "taxon") |>
dplyr::mutate(diff = newCount - previousCount)
unique(newCounts$taxon)
sort(unique(newCounts$taxon))
sort(unique(prevCounts))
sort(unique(prevCounts$taxon))
newCounts <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)|>
dplyr::select(newCount = n)
dim(newCounts)
dim(prevCounts)
unique(newCounts$taxon)
View(d8)
# add the G records with no lat lon back to the modeling data---------------------------------------
d6 <- valLatLon |> bind_rows(d3_g)
View(d6)
#more duplicate checks
d <- d6[!duplicated(d6[,c("taxon", "databaseSource" , "sourceUniqueID")]), ]
View(d)
# remove midwest herb
d8 <- d[!d$databaseSource == "Midwest Herbaria 2019", ]
VieW(d8)
VieW(d8)
View(d8)
# remove NA taxon
d8 <- d |>
dplyr::filter(!is.na(taxon))
d8
View(d8)
write_csv(x = d8, file = "data/processed_occurrence/model_data122025.csv")
t1<- read_csv("temp/allVitisData082025.csv")
# get counts per taxon and compare to see what needs alterations
prevCounts <- t1 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE) |>
dplyr::select(previousCount = n) |>
dplyr::filter(!is.na(taxon))
newCounts <- d8 |>
dplyr::group_by(taxon)|>
dplyr::count( sort =TRUE)|>
dplyr::select(newCount = n)
dim(newCounts)
dim(prevCounts)
joined <- dplyr::left_join(newCounts, prevCounts, by = "taxon") |>
dplyr::mutate(
changeInNumber = newCount = previousCount
joined <- dplyr::left_join(newCounts, prevCounts, by = "taxon") |>
dplyr::mutate(
changeInNumber = newCount - previousCount
)
View(joined)
VieW(d8)
View(d8)
View(joined)
write_csv(joined, "temp/changeInCounts.csv")
